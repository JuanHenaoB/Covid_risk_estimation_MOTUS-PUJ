{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Manejo de bases de datos\n",
    "import geopandas as gpd # Manejo de bases de datos geográficas\n",
    "import numpy as np # Funciones numéricas\n",
    "import matplotlib.pyplot as plt # Gráficas\n",
    "import seaborn as sns # Gráficas\n",
    "import datetime as dt\n",
    "import folium\n",
    "import unicodedata\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "from branca.colormap import linear\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Death's by locality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################\n",
    "################################ Preparing Data for Bogotá city  #######################################\n",
    "########################################################################################################\n",
    "\n",
    "# Get death count from epidemiological report\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "#Excel file with Bogotá localities, id, latitude and longitude  \n",
    "path = \"/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/Files/Localidades_Nombres.xlsx\"\n",
    "Bog = pd.read_excel(path, sheet_name='Hoja1')\n",
    "\n",
    "# Bogota info DF provided by local Town Hall\n",
    "path = \"/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/Files/georeferencia-puntual-por-localidad.csv\"\n",
    "geoBog = pd.read_csv(path, encoding = 'UTF-8',  sep='\\t', delimiter=\";\")\n",
    "geoBog = geoBog.sort_values(by='CODIGO', ascending=True)\n",
    "\n",
    "# CSV containing confirmed Covid-19 cases in Bogotá sorted by localities \n",
    "# a locality is a big region in Bogotá city. Inside every locality there are several neighbourhoods\n",
    "path = \"/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/Files/casos_confirmados_Bog.csv\"\n",
    "CovidBog = pd.read_csv(path, encoding = \"UTF-8\", sep='\\t', delimiter=\";\", low_memory=False)\n",
    "\n",
    "del path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In CovidBog DF\n",
    "# Drop Cols we don´t need\n",
    "CovidBog = CovidBog.drop(columns=['EDAD', 'FUENTE_O_TIPO_DE_CONTAGIO', 'UBICACION', 'CIUDAD', 'UNI_MED', 'SEXO', 'CASO' ])\n",
    "\n",
    "# add some cols in order to write in them needed data \n",
    "CovidBog['CODIGO_LOCALIDAD'] = 0 \n",
    "\n",
    "# Re-order cols \n",
    "CovidBog = CovidBog.reindex(columns=['FECHA_DE_INICIO_DE_SINTOMAS', 'FECHA_DIAGNOSTICO', 'LOCALIDAD_ASIS', 'CODIGO_LOCALIDAD', 'ESTADO'])\n",
    "\n",
    "# Delete rows with missing values \n",
    "CovidBog = CovidBog.dropna(axis=0, how='any', subset=['FECHA_DIAGNOSTICO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing all locality strings to lower_case and taking off accents\n",
    "trans_tab = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n",
    "\n",
    "#Bog DF\n",
    "Bog['Localidad'] = Bog.apply(lambda row: row['Localidad'].lower(), axis=1)\n",
    "Bog['Localidad'] = Bog.apply(lambda row: normalize('NFKC', normalize('NFKD', row['Localidad']).translate(trans_tab)), axis=1)\n",
    "\n",
    "#geoBog DF\n",
    "geoBog['LOCALIDAD'] = geoBog.apply(lambda row: row['LOCALIDAD'].lower(), axis=1)\n",
    "geoBog['LOCALIDAD'] = geoBog.apply(lambda row: normalize('NFKC', normalize('NFKD', row['LOCALIDAD']).translate(trans_tab)), axis=1)\n",
    "\n",
    "#CovidBog DF\n",
    "CovidBog['LOCALIDAD_ASIS'] = CovidBog.apply(lambda row: row['LOCALIDAD_ASIS'].lower(), axis=1)\n",
    "CovidBog['LOCALIDAD_ASIS'] = CovidBog.apply(lambda row: normalize('NFKC', normalize('NFKD', row['LOCALIDAD_ASIS']).translate(trans_tab)), axis=1)\n",
    "\n",
    "#delete vars no longer used \n",
    "del trans_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Equal FECHA_DE_INICIO_DE_SINTOMAS to FECHA_DIAGNOSTICO when FECHA_DE_INICIO_DE_SINTOMAS = NaN\n",
    "#Detect NaN Sympthoms date\n",
    "CovidBog['AUX'] = CovidBog['FECHA_DE_INICIO_DE_SINTOMAS'].isna() \n",
    "\n",
    "#Change NaN Dates by diagnosis date. \n",
    "#CovidBog['FECHA_DE_INICIO_DE_SINTOMAS'] = CovidBog.apply(lambda row: row['FECHA_DIAGNOSTICO'] if row['FECHA_DE_INICIO_DE_SINTOMAS'].isna() == True else row['FECHA_DE_INICIO_DE_SINTOMAS'], axis=1)\n",
    "CovidBog['FECHA_DE_INICIO_DE_SINTOMAS'] = CovidBog.apply(lambda row: row['FECHA_DIAGNOSTICO'] if row['AUX'] == True else row['FECHA_DE_INICIO_DE_SINTOMAS'], axis=1)\n",
    "CovidBog = CovidBog.drop(columns=['AUX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################\n",
    "########### Declare variables and lists used in code to asign/calculate localities, latitude, longitude #####\n",
    "#############################################################################################################\n",
    "\n",
    "#Localities name list \n",
    "Loc_hist_names = list(Bog['Localidad'])\n",
    "\n",
    "#Local id code list\n",
    "Loc_codes = list(range(len(Loc_hist_names)))\n",
    "\n",
    "#############################################################################\n",
    "################## method used for filling local ID code ####################\n",
    "#############################################################################\n",
    "def local_ID (localidad):\n",
    "    for i in range(len(Loc_hist_names)):\n",
    "        if localidad == Loc_hist_names[i]:\n",
    "            return Loc_codes[i]\n",
    "        \n",
    "#Asign local ID code \n",
    "CovidBog['CODIGO_LOCALIDAD'] = CovidBog.apply(lambda row: local_ID(row['LOCALIDAD_ASIS']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_DE_INICIO_DE_SINTOMAS</th>\n",
       "      <th>FECHA_DIAGNOSTICO</th>\n",
       "      <th>LOCALIDAD_ASIS</th>\n",
       "      <th>CODIGO_LOCALIDAD</th>\n",
       "      <th>ESTADO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>barrios unidos</td>\n",
       "      <td>12</td>\n",
       "      <td>Fallecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>kennedy</td>\n",
       "      <td>8</td>\n",
       "      <td>Fallecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>2020-03-29</td>\n",
       "      <td>usaquen</td>\n",
       "      <td>1</td>\n",
       "      <td>Fallecido</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA_DE_INICIO_DE_SINTOMAS FECHA_DIAGNOSTICO  LOCALIDAD_ASIS  \\\n",
       "0                  2020-03-06        2020-03-26  barrios unidos   \n",
       "1                  2020-03-07        2020-03-29         kennedy   \n",
       "2                  2020-03-07        2020-03-29         usaquen   \n",
       "\n",
       "   CODIGO_LOCALIDAD     ESTADO  \n",
       "0                12  Fallecido  \n",
       "1                 8  Fallecido  \n",
       "2                 1  Fallecido  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change str Dates to Datetime objects\n",
    "CovidBog['FECHA_DIAGNOSTICO'] = pd.to_datetime(CovidBog['FECHA_DIAGNOSTICO'], format='%Y/%m/%d')\n",
    "CovidBog['FECHA_DE_INICIO_DE_SINTOMAS'] = pd.to_datetime(CovidBog['FECHA_DE_INICIO_DE_SINTOMAS'], format='%Y/%m/%d')\n",
    "\n",
    "#Re organize rows by ascending datetime object\n",
    "CovidBog = CovidBog.sort_values(by='FECHA_DE_INICIO_DE_SINTOMAS', ascending=True)\n",
    "CovidBog = CovidBog.reset_index(drop=True)\n",
    "\n",
    "# Filter for death cases\n",
    "CovidDeath = CovidBog.copy()\n",
    "CovidDeath = CovidDeath[ CovidDeath['ESTADO'] != 'Recuperado' ]\n",
    "CovidDeath.reset_index(drop=True, inplace=True)\n",
    "\n",
    "CovidDeath.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FECHA_DIAGNOSTICO</th>\n",
       "      <th>CODIGO_LOCALIDAD</th>\n",
       "      <th>FALLECIDOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  FECHA_DIAGNOSTICO  CODIGO_LOCALIDAD  FALLECIDOS\n",
       "0        2020-03-20                 1           1\n",
       "1        2020-03-20                16           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group deaths so we can count them in the same form we count active cases\n",
    "\n",
    "#Group historic reports by date and localities\n",
    "deaths = CovidDeath.groupby(['FECHA_DIAGNOSTICO', 'CODIGO_LOCALIDAD'])['LOCALIDAD_ASIS'].count()\n",
    "deaths = pd.DataFrame(deaths)\n",
    "deaths.reset_index(drop=False, inplace=True)\n",
    "\n",
    "deaths = deaths.rename(columns={'LOCALIDAD_ASIS': 'FALLECIDOS'})#Rename Column\n",
    "\n",
    "#Change str to datetime objects\n",
    "deaths['FECHA_DIAGNOSTICO'] = pd.to_datetime(deaths['FECHA_DIAGNOSTICO'], format='%Y-%m-%d')\n",
    "deaths = deaths.sort_values(by='FECHA_DIAGNOSTICO', ascending=True)\n",
    "deaths = deaths.reset_index(drop=True)\n",
    "\n",
    "#Drop 0 and 21 id codes since they don´t belong to Bogotá geography \n",
    "index_0 = deaths[ deaths['CODIGO_LOCALIDAD'] == 0 ].index\n",
    "index_21 = deaths[ deaths['CODIGO_LOCALIDAD'] == 21 ].index\n",
    "deaths.drop(index_0, inplace = True)#drop fuera de bogotá and sin dato rows since we cannot calculate infection \n",
    "deaths.drop(index_21, inplace = True)# density for them (we don´t know their reference population)\n",
    "\n",
    "deaths.reset_index(drop=True, inplace=True)\n",
    "deaths.to_pickle('/home/ubuntu/javeriana/MOTUS-PUJ/Step_3/Outputs/death_count.pkl')\n",
    "deaths.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "7345    None\n",
       "7346    None\n",
       "7347    None\n",
       "7348    None\n",
       "7349    None\n",
       "Length: 7350, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_index = len(deaths['FECHA_DIAGNOSTICO']) #column length \n",
    "start_date = deaths.loc[0, 'FECHA_DIAGNOSTICO'] #start of the pandemic in Bogotá \n",
    "end_date = deaths.loc[com_index-1, 'FECHA_DIAGNOSTICO'] #Last reported date \n",
    "\n",
    "pan_days = end_date - start_date\n",
    "pan_days = int(pan_days.days) #Days passed since pandemic start to last reported date grid x axis \n",
    "local_bog = len(Loc_hist_names) - 2 # number of rows y axis we are not considering 0 and 21 codes \n",
    "\n",
    "#create grid and fill it with reported cases y axis correspond to Bogota localities id code, x axis correspond to \n",
    "#number of days passed since pandemic started that way 0 index -> 2020-02-06, 1->2020-02-07 and so on\n",
    "\n",
    "grid = np.ndarray([local_bog, pan_days+1]) #create grid\n",
    "grid.fill(0) #fill grid with 0 \n",
    "\n",
    "#Method used to fill grid with reported cases \n",
    "def fillGrid(date, code, cases):\n",
    "    col = date - start_date\n",
    "    col = int(col.days)\n",
    "    grid[code-1][col] = cases\n",
    "    \n",
    "\n",
    "#Fill grid with cases \n",
    "deaths.apply(lambda row: fillGrid(row['FECHA_DIAGNOSTICO'], row['CODIGO_LOCALIDAD'], int(row['FALLECIDOS']) ), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Estimated RT for each locality \n",
    "# Reading localities R_t\n",
    "base_path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/RT_outputs/'\n",
    "\n",
    "loc_R_list = ['usaquen.pkl', 'chapinero.pkl', 'santafe.pkl', 'sancristobal.pkl', 'usme.pkl',\n",
    "             'tunjuelito.pkl', 'bosa.pkl', 'kennedy.pkl', 'fontibon.pkl', 'engativa.pkl',\n",
    "             'suba.pkl', 'barriosunidos.pkl', 'teusaquillo.pkl', 'losmartires.pkl', 'antonionariño.pkl',\n",
    "             'puentearanda.pkl', 'lacandelaria.pkl', 'rafaeluribeuribe.pkl', 'ciudadbolivar.pkl']\n",
    "\n",
    "R_list = []\n",
    "# Load data frames, reset index\n",
    "for i in range(len(loc_R_list)):\n",
    "    path_file = base_path+loc_R_list[i]\n",
    "    R_list.append(pd.read_pickle(path_file))\n",
    "    \n",
    "for i in range(len(loc_R_list)):\n",
    "    R_list[i].reset_index(drop=False, inplace=True)\n",
    "    \n",
    "# Create DF containing all RT scores for each locality \n",
    "R_df = pd.DataFrame(index = R_list[0]['Time Stamp'])\n",
    "R_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "for i in range(len(loc_R_list)):\n",
    "    R_df[loc_R_list[i]] = 0\n",
    "    R_df[loc_R_list[i]] = R_list[i]['R'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to count deaths past 15 days\n",
    "def ActiveCases (date, code):\n",
    "    col = date - start_date\n",
    "    col = int(col.days)\n",
    "    if col >= 15:\n",
    "        Active = sum(grid[code-1][col-15:col+1])\n",
    "    else: \n",
    "        Active = sum(grid[code-1][0:col+1])\n",
    "    return int(Active)\n",
    "\n",
    "Loc_codes = list(range(1,20))\n",
    "# Make a map to compare localities risk evaluated by death and RT vs UTAMs risk\n",
    "\n",
    "date_list = ['01/05/2020', '01/08/2020', '10/01/2021', '10/03/2021', '20/06/2021'] # d m Y\n",
    "date_list2 = ['01-05-2020', '01-08-2020', '10-01-2021', '10-03-2021', '20-06-2021']\n",
    "\n",
    "#date_list = ['01/05/2020' ,'01/08/2020', '01/11/2020', '10/01/2021', '10/03/2021', '01/05/2021',\n",
    "#             '20/06/2021', '01/09/2021']\n",
    "\n",
    "#date_list2 = ['01-05-2020' ,'01-08-2020', '01-11-2020', '10-01-2021', '10-03-2021', '01-05-2021',\n",
    "#             '20-06-2021', '01-09-2021']\n",
    "\n",
    "#Count deahts and RT for each locality at designed dates\n",
    "#Count deaths\n",
    "death_count = []\n",
    "for i in range(len(date_list)):\n",
    "    date = dt.datetime.strptime(date_list[i], \"%d/%m/%Y\")\n",
    "    temp = []\n",
    "    for j in range (len(Loc_codes)):\n",
    "        temp.append(ActiveCases(date, Loc_codes[j]))\n",
    "        \n",
    "    death_count.append(temp)\n",
    "    del temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count RT at designed dates\n",
    "RT_listD = []\n",
    "for i in range(len(date_list)):\n",
    "    date = dt.datetime.strptime(date_list[i], \"%d/%m/%Y\")\n",
    "    rt_list = R_df[ R_df['Time Stamp'] == date ]\n",
    "    rt_list = rt_list.iloc[:, 1:].values.tolist()[0]\n",
    "    RT_listD.append(rt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize values in each date \n",
    "RT_listDN = RT_listD.copy()\n",
    "death_countN = death_count.copy()\n",
    "\n",
    "for i in range(len(date_list)):\n",
    "    maax = max(RT_listDN[i])\n",
    "    dmax = max(death_count[i])\n",
    "    for j in range(len(Loc_codes)):\n",
    "        RT_listDN[i][j] = RT_listDN[i][j]/maax\n",
    "        death_countN[i][j] = death_countN[i][j]/dmax\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute score similar to the one computed for deciding risk levels at clustering\n",
    "score = []\n",
    "for i in range(len(date_list)):\n",
    "    temp = []\n",
    "    for j in range(len(Loc_codes)):\n",
    "        temp.append(RT_listDN[i][j]+death_countN[i][j])\n",
    "    score.append(temp)\n",
    "    del temp\n",
    "    \n",
    "# Finally execute labeling for this score\n",
    "manual_label = []\n",
    "for i in range(len(date_list)):\n",
    "    temp = []\n",
    "    for j in range(len(Loc_codes)):\n",
    "        if score[i][j] <= 0.8:\n",
    "            temp.append(0)\n",
    "        if score[i][j] > 0.8 and score[i][j] <= 1.4:\n",
    "            temp.append(1)\n",
    "        if score[i][j] > 1.4:\n",
    "            temp.append(2)\n",
    "    manual_label.append(temp)\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read UTAM clustered DFs to compare them with localities\n",
    "base_path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_3/Files/ClustDFs/'\n",
    "ClustUtam = []\n",
    "for i in range(len(date_list2)):\n",
    "    name = base_path+'date_'+date_list2[i]+'.pkl'\n",
    "    temp = pd.read_pickle(name)\n",
    "    temp = gpd.GeoDataFrame(temp)\n",
    "    temp.crs = 'EPSG:4326'\n",
    "    temp.to_crs(epsg=4326, inplace=True)\n",
    "    ClustUtam.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocNombre</th>\n",
       "      <th>LocCodigo</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>usaquen</td>\n",
       "      <td>1</td>\n",
       "      <td>POLYGON ((-74.01116 4.66459, -74.01117 4.66460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chapinero</td>\n",
       "      <td>2</td>\n",
       "      <td>POLYGON ((-74.01116 4.66459, -74.01154 4.66461...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocNombre  LocCodigo                                           geometry\n",
       "0    usaquen          1  POLYGON ((-74.01116 4.66459, -74.01117 4.66460...\n",
       "1  chapinero          2  POLYGON ((-74.01116 4.66459, -74.01154 4.66461..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a map \n",
    "# Make a map\n",
    "def Arreglar_tilde(Texto):\n",
    "    Texto = unicodedata.normalize('NFD', Texto)\n",
    "    Texto = Texto.encode('ascii', 'ignore')\n",
    "    Texto = Texto.decode(\"utf-8\")\n",
    "    Texto = Texto.lower()\n",
    "    return(Texto)\n",
    "\n",
    "path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_2/1_spatial/spatial_features/Locality/Loca.shp'\n",
    "Localities = gpd.read_file(path)\n",
    "Localities = Localities.sort_values(by='LocCodigo', ascending=True)\n",
    "Localities = Localities.reset_index(drop=True)\n",
    "Localities['LocCodigo'] = pd.to_numeric(Localities['LocCodigo'], downcast='integer')\n",
    "Localities.to_crs(epsg=4326, inplace=True)\n",
    "Localities.drop(columns=['LocAAdmini', 'LocArea', 'SHAPE_Leng', 'SHAPE_Area'], inplace=True)\n",
    "Localities['LocNombre'] = Localities.apply(lambda row: Arreglar_tilde(row['LocNombre']), axis=1)\n",
    "Localities.drop(19, axis=0, inplace=True)\n",
    "Localities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init folium map object for Bogotá\n",
    "Lat = 4.61\n",
    "Long = -74.082\n",
    "m = folium.Map(location=[Lat, Long], zoom_start=12, tiles='CartoDB positron')\n",
    "\n",
    "feature_group1 = folium.FeatureGroup(name=date_list[0]+'Loc' ,overlay=True, show=False).add_to(m)\n",
    "feature_group2 = folium.FeatureGroup(name=date_list[1]+'Loc' ,overlay=True, show=False).add_to(m)\n",
    "feature_group3 = folium.FeatureGroup(name=date_list[2]+'Loc' ,overlay=True, show=False).add_to(m)\n",
    "feature_group4 = folium.FeatureGroup(name=date_list[3]+'Loc' ,overlay=True, show=False).add_to(m)\n",
    "feature_group5 = folium.FeatureGroup(name=date_list[4]+'Loc' ,overlay=True, show=False).add_to(m)\n",
    "\n",
    "feature_group6 = folium.FeatureGroup(name=date_list[0]+'Utam' ,overlay=False).add_to(m)\n",
    "feature_group7 = folium.FeatureGroup(name=date_list[1]+'Utam' ,overlay=False).add_to(m)\n",
    "feature_group8 = folium.FeatureGroup(name=date_list[2]+'Utam' ,overlay=False).add_to(m)\n",
    "feature_group9 = folium.FeatureGroup(name=date_list[3]+'Utam' ,overlay=False).add_to(m)\n",
    "feature_group10 = folium.FeatureGroup(name=date_list[4]+'Utam' ,overlay=False).add_to(m)\n",
    "\n",
    "fs = [feature_group1, feature_group2, feature_group3, feature_group4, \n",
    "      feature_group5, feature_group6, feature_group7, feature_group8, \n",
    "      feature_group9, feature_group10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.map.LayerControl at 0x7ff2c9c6d9d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(date_list)):\n",
    "    LocTemp = Localities.copy()\n",
    "    LocTemp['Manual_label'] = manual_label[i]\n",
    "    choropleth1 = folium.Choropleth(\n",
    "    geo_data=LocTemp,\n",
    "    name='choropleth',\n",
    "    data=LocTemp,\n",
    "    columns=['LocNombre', 'Manual_label'],\n",
    "    key_on='feature.properties.LocNombre',\n",
    "    fill_color='YlOrRd',\n",
    "    nan_fill_color=\"white\",\n",
    "    fill_opacity=0.5,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Strat_risk',\n",
    "    highlight=True,\n",
    "    line_color='black').geojson.add_to(fs[i])\n",
    "    \n",
    "    geojson1 = folium.GeoJson(data=LocTemp, \n",
    "                              name='Localidades', \n",
    "                              smooth_factor=2, \n",
    "                              style_function=lambda x: {'color':'black','fillColor':'transparent','weight':0.5}, \n",
    "                              tooltip=folium.GeoJsonTooltip(fields=['Manual_label'],\n",
    "                                                            aliases=['label Manual'],\n",
    "                                                            labels=True, \n",
    "                                                            sticky=True), \n",
    "                              highlight_function=lambda x: {'weight':3,'fillColor':'grey'}, \n",
    "                             ).add_to(choropleth1)\n",
    "    \n",
    "    choropleth2 = folium.Choropleth(\n",
    "    geo_data=ClustUtam[i],\n",
    "    name='choropleth2',\n",
    "    data=ClustUtam[i],\n",
    "    columns=['UTAMNombre', 'Risk'],\n",
    "    key_on='feature.properties.UTAMNombre',\n",
    "    fill_color='YlOrRd',\n",
    "    nan_fill_color=\"white\",\n",
    "    fill_opacity=1,\n",
    "    line_opacity=0.2,\n",
    "    legend_name='Strat_risk',\n",
    "    highlight=True,\n",
    "    line_color='black').geojson.add_to(fs[i+5])\n",
    "    \n",
    "    geojson1 = folium.GeoJson(data=ClustUtam[i], \n",
    "                              name='UTAM', \n",
    "                              smooth_factor=2, \n",
    "                              style_function=lambda x: {'color':'black','fillColor':'transparent','weight':0.5}, \n",
    "                              tooltip=folium.GeoJsonTooltip(fields=['Risk'],\n",
    "                                                            aliases=['Strat Clust Risk'],\n",
    "                                                            labels=True, \n",
    "                                                            sticky=True), \n",
    "                              highlight_function=lambda x: {'weight':3,'fillColor':'grey'}, \n",
    "                             ).add_to(choropleth2)\n",
    "\n",
    "    \n",
    "colormap = linear.YlOrRd_09.scale(0, 2).to_step(2)\n",
    "colormap.caption = 'Strat_risk'\n",
    "colormap.add_to(m)\n",
    "\n",
    "folium.TileLayer('cartodbpositron', overlay=True, name=\"light mode\").add_to(m)\n",
    "folium.LayerControl(collapsed=False).add_to(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.save('/home/ubuntu/javeriana/MOTUS-PUJ/Graficas/Implementacion/UtamVSloc.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean risk label by locality \n",
    "MeanClustLoc = []\n",
    "for i in range(len(date_list)):\n",
    "    temp = []\n",
    "    for j in range(len(Loc_codes)):\n",
    "        df = ClustUtam[i][ClustUtam[i]['LOCid'] == Loc_codes[j]]\n",
    "        tot = sum(df['Risk'].values.tolist())\n",
    "        mean = tot/len(df['Risk'])\n",
    "        temp.append(mean)\n",
    "    MeanClustLoc.append(temp)\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Square Error function\n",
    "def ECM(R_Bog, R_Al):\n",
    "    ecm = 0\n",
    "    for i in range(len(R_Bog)):\n",
    "        ecm += (R_Al[i] - R_Bog[i])**2\n",
    "    ecm = ecm/len(R_Bog)\n",
    "    return ecm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare UTAM risk with manual risk\n",
    "UtamECM = []\n",
    "for i in range(len(manual_label)):\n",
    "    UtamECM.append(ECM(MeanClustLoc[i], manual_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.18170305061595787,\n",
       " 0.15986825529432047,\n",
       " 0.1491812865497076,\n",
       " 0.1328012905942104,\n",
       " 0.22533801434803943]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UtamECM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Route error (city block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Loc manual labels with mean labels \n",
    "base_path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_3/Files/ClassDFs/'\n",
    "cityBlockDF = []\n",
    "for i in range(len(date_list2)):\n",
    "    name = base_path+'date_'+date_list2[i]+'.pkl'\n",
    "    temp = pd.read_pickle(name, compression='gzip')\n",
    "    temp = gpd.GeoDataFrame(temp)\n",
    "    temp.crs = 'EPSG:4326'\n",
    "    temp.to_crs(epsg=4326, inplace=True)\n",
    "    cityBlockDF.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean risk label city block to locality\n",
    "MeanClustBlock = []\n",
    "for i in range(len(date_list)):\n",
    "    temp = []\n",
    "    for j in range(len(Loc_codes)):\n",
    "        df = cityBlockDF[i][cityBlockDF[i]['LOCid'] == Loc_codes[j]]\n",
    "        tot = sum(df['RiskStrat'].values.tolist())\n",
    "        mean = tot/len(df['RiskStrat'])\n",
    "        temp.append(mean)\n",
    "    MeanClustBlock.append(temp)\n",
    "    del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "CityBlockECM = []\n",
    "for i in range(len(manual_label)):\n",
    "    CityBlockECM.append(ECM(MeanClustBlock[i], manual_label[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.15751484937638857,\n",
       " 0.2630958959137962,\n",
       " 0.3652503546495923,\n",
       " 0.26192795636655736,\n",
       " 0.5131539578419445]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CityBlockECM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
