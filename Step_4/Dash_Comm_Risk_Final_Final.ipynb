{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Manejo de bases de datos\n",
    "import geopandas as gpd # Manejo de bases de datos geográficas\n",
    "import numpy as np # Funciones numéricas\n",
    "import matplotlib.pyplot as plt # Gráficas\n",
    "import seaborn as sns # Gráficas\n",
    "import datetime as dt\n",
    "import folium\n",
    "import unicodedata\n",
    "import geojson\n",
    "import urllib, json\n",
    "import base64\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import neighbors\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from shapely.geometry import LineString, Point\n",
    "from geopandas.tools import sjoin\n",
    "from branca.colormap import linear\n",
    "\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output\n",
    "import visdcc\n",
    "from waitress import serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data needed to create DashBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\acer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:22: FutureWarning:\n",
      "\n",
      "Your version of xlrd is 1.2.0. In xlrd >= 2.0, only the xls format is supported. As a result, the openpyxl engine will be used if it is installed and the engine argument is not specified. Install openpyxl instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "############## Read Bogota spatial characteristics previously prepared and organized.###############\n",
    "####################################################################################################\n",
    "path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_2/2_ML_Preps/Outputs/partial_spatial_utam.pkl'\n",
    "spatial_utam = pd.read_pickle(path, compression='gzip')\n",
    "spatial_utam = gpd.GeoDataFrame(spatial_utam)\n",
    "spatial_utam.crs = 'EPSG:4326'\n",
    "spatial_utam.to_crs(epsg=4326, inplace=True)\n",
    "\n",
    "###################################################################################################\n",
    "#########################Estimate UTAM population weight vector####################################\n",
    "###################################################################################################\n",
    "def Arreglar_tilde(Texto):\n",
    "    Texto = unicodedata.normalize('NFD', Texto)\n",
    "    Texto = Texto.encode('ascii', 'ignore')\n",
    "    Texto = Texto.decode(\"utf-8\")\n",
    "    Texto = Texto.lower()\n",
    "    return(Texto)\n",
    "\n",
    "# Bogotá localities population\n",
    "path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/Files/Poblacion_Bogota.xlsx'\n",
    "PobBog = pd.read_excel(path, sheet_name='1.1')\n",
    "PobBog = PobBog.drop([PobBog.index[0], PobBog.index[1], PobBog.index[2], PobBog.index[3], PobBog.index[4], \n",
    "                      PobBog.index[25], PobBog.index[26]])\n",
    "#Rename columns\n",
    "PobBog = PobBog.filter(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 17', 'Unnamed: 18'])\n",
    "PobBog = PobBog.rename(columns={'Unnamed: 0': 'id localidad', 'Unnamed: 1': 'localidad',\n",
    "                                     'Unnamed: 17': 'Población 2020', 'Unnamed: 18': 'Población 2021'})\n",
    "#Sorting Dataframe by locality id \n",
    "PobBog['id localidad'] = pd.to_numeric(PobBog['id localidad'])\n",
    "PobBog.sort_values(by='id localidad', ascending=True)\n",
    "PobBog.drop(columns={'Población 2020'}, inplace=True)\n",
    "PobBog.reset_index(drop=True, inplace=True)\n",
    "#Lower case and taking off accent marks\n",
    "PobBog['localidad'] = PobBog.apply(lambda row: Arreglar_tilde(row['localidad']), axis=1)\n",
    "pop_list = PobBog['Población 2021'].tolist()\n",
    "\n",
    "# Localities codes are ascending numbers from 1 to 19\n",
    "Loc_code = list(range(1,20))\n",
    "\n",
    "LocHomes = []\n",
    "for i in range(len(Loc_code)):\n",
    "    #For each locality count the number of homes within it\n",
    "    temp = spatial_utam[ spatial_utam['LOCid'] == Loc_code[i] ]\n",
    "    temp_list = temp['HOGARES'].values.tolist()\n",
    "    tot_homes = sum(temp_list)\n",
    "    LocHomes.append(tot_homes)\n",
    "    \n",
    "ppl_weight = []\n",
    "#Estimate the mean number of people each home needs to match locality population\n",
    "for i in range(len(LocHomes)):\n",
    "    temp = pop_list[i]/LocHomes[i]\n",
    "    ppl_weight.append(temp)\n",
    "    \n",
    "del LocHomes, PobBog\n",
    "\n",
    "###################################################################################################\n",
    "############################Load RT estimated for each locality####################################\n",
    "###################################################################################################\n",
    "base_path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/RT_outputs/'\n",
    "\n",
    "loc_R_list = ['usaquen.pkl', 'chapinero.pkl', 'santafe.pkl', 'sancristobal.pkl', 'usme.pkl',\n",
    "             'tunjuelito.pkl', 'bosa.pkl', 'kennedy.pkl', 'fontibon.pkl', 'engativa.pkl',\n",
    "             'suba.pkl', 'barriosunidos.pkl', 'teusaquillo.pkl', 'losmartires.pkl', 'antonionariño.pkl',\n",
    "             'puentearanda.pkl', 'lacandelaria.pkl', 'rafaeluribeuribe.pkl', 'ciudadbolivar.pkl']\n",
    "\n",
    "R_list = []\n",
    "\n",
    "for i in range(len(loc_R_list)):\n",
    "    path_file = base_path+loc_R_list[i]\n",
    "    R_list.append(pd.read_pickle(path_file))\n",
    "    \n",
    "for i in range(len(loc_R_list)):\n",
    "    R_list[i].reset_index(drop=False, inplace=True)\n",
    "    \n",
    "R_df = pd.DataFrame(index = R_list[0]['Time Stamp'])\n",
    "R_df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "for i in range(len(loc_R_list)):\n",
    "    R_df[loc_R_list[i]] = 0\n",
    "    R_df[loc_R_list[i]] = R_list[i]['R'].tolist()\n",
    "    \n",
    "###################################################################################################\n",
    "###########################Active cases count for each locality####################################\n",
    "###################################################################################################\n",
    "#fechas_df = pd.read_csv('/home/ubuntu/javeriana/MOTUS-PUJ/Bog_Estimation/ECM/fechas_sintomas.csv')\n",
    "fechas_df = pd.read_csv('/home/ubuntu/javeriana/MOTUS-PUJ/Step_1/Outputs/fechas_sintomas.csv')\n",
    "fechas_df = fechas_df.rename(columns={'LOCALIDAD_ASIS': 'CASOS_REPORTADOS'})#Rename Column\n",
    "\n",
    "#Change str to datetime objects\n",
    "fechas_df['FECHA_DE_INICIO_DE_SINTOMAS'] = pd.to_datetime(fechas_df['FECHA_DE_INICIO_DE_SINTOMAS'], format='%Y-%m-%d')\n",
    "fechas_df = fechas_df.sort_values(by='FECHA_DE_INICIO_DE_SINTOMAS', ascending=True)\n",
    "fechas_df = fechas_df.reset_index(drop=True)\n",
    "\n",
    "#Drop 0 and 21 id codes since they don´t belong to Bogotá geography \n",
    "index_0 = fechas_df[ fechas_df['CODIGO_LOCALIDAD'] == 0 ].index\n",
    "index_21 = fechas_df[ fechas_df['CODIGO_LOCALIDAD'] == 21 ].index\n",
    "\n",
    "fechas_df.drop(index_0, inplace = True)#drop fuera de bogotá and sin dato rows since we cannot calculate infection \n",
    "fechas_df.drop(index_21, inplace = True)# density for them (we don´t know their reference population)\n",
    "\n",
    "fechas_df = fechas_df.reset_index(drop = True)\n",
    "\n",
    "com_index = len(fechas_df['FECHA_DE_INICIO_DE_SINTOMAS']) #column length \n",
    "start_date = fechas_df.loc[0, 'FECHA_DE_INICIO_DE_SINTOMAS'] #start of the pandemic in Bogotá \n",
    "end_date = fechas_df.loc[com_index-1, 'FECHA_DE_INICIO_DE_SINTOMAS'] #Last reported date \n",
    "\n",
    "pan_days = end_date - start_date\n",
    "pan_days = int(pan_days.days) #Days passed since pandemic start to last reported date grid x axis \n",
    "local_bog = 20 # number of rows y axis we are not considering 0 and 21 codes \n",
    "\n",
    "#create grid and fill it with reported cases y axis correspond to Bogota localities id code, x axis correspond to \n",
    "#number of days passed since pandemic started that way 0 index -> 2020-02-06, 1->2020-02-07 and so on\n",
    "\n",
    "grid = np.ndarray([local_bog, pan_days+1]) #create grid\n",
    "grid.fill(0) #fill grid with 0 \n",
    "\n",
    "#Method used to fill grid with reported cases \n",
    "def fillGrid(date, code, cases):\n",
    "    col = date - start_date\n",
    "    col = int(col.days)\n",
    "    grid[code-1][col] = cases\n",
    "    \n",
    "\n",
    "#Fill grid with cases \n",
    "fechas_df.apply(lambda row: fillGrid(row['FECHA_DE_INICIO_DE_SINTOMAS'], row['CODIGO_LOCALIDAD'], int(row['CASOS_REPORTADOS']) ), axis=1)\n",
    "#function to count active cases in determined date\n",
    "def ActiveCases (date, code):\n",
    "    col = date - start_date\n",
    "    col = int(col.days)\n",
    "    if col >= 15:\n",
    "        Active = sum(grid[code-1][col-15:col+1])\n",
    "    else: \n",
    "        Active = sum(grid[code-1][0:col+1])\n",
    "    return int(Active)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_cases(weight, caseLoc, PobLoc, ID, Hog):\n",
    "    x = (100*caseLoc)/(PobLoc)\n",
    "    y = (x*weight[ID-1]*Hog)/100\n",
    "    return y\n",
    "\n",
    "def singularizeRT(loc, estrato, popden, hosp, ips, itur, sitp, comer, trips, cases, RT):\n",
    "    if loc == 'candelaria':\n",
    "        return RT\n",
    "    else:\n",
    "        a_rt = RT-estrato+popden-hosp-ips+itur+sitp+comer+trips+cases\n",
    "        return a_rt\n",
    "    \n",
    "def ClusteringPrepDF(selec_date, selec_str, spatial_utam):\n",
    "    #Add Active cases in interest date at locality level\n",
    "    Active_cases = []\n",
    "    for i in range(len(Loc_code)):\n",
    "        Active_cases.append(ActiveCases(selec_date, Loc_code[i]))\n",
    "        \n",
    "    #Add Active Cases\n",
    "    spatial_utam_date = spatial_utam.copy()    \n",
    "    spatial_utam_date['cases'+selec_str] = spatial_utam_date.apply(lambda row: Active_cases[row['LOCid']-1], axis=1)\n",
    "    #Estimate Active cases in a lower geographical level\n",
    "    spatial_utam_date['UTAM_cases'+selec_str] = spatial_utam_date.apply(lambda row: single_cases(ppl_weight, \n",
    "                                                                                                  row['cases'+selec_str], \n",
    "                                                                                                  row['PopLoc'], row['LOCid'], \n",
    "                                                                                                  row['HOGARES']), axis=1)\n",
    "    #Locality RT in interest date\n",
    "    rt_list = R_df[ R_df['Time Stamp'] == selec_date ]\n",
    "    rt_list = rt_list.iloc[:, 1:].values.tolist()[0]\n",
    "    #Add RT to DataFrame\n",
    "    spatial_utam_date['Rt'+selec_str] = spatial_utam_date.apply(lambda row: rt_list[row['LOCid']-1], axis=1)\n",
    "    #Estimate RT in a lower geographical level\n",
    "    spatial_utam_date['Total trips'] = spatial_utam_date['originated Trips']+spatial_utam_date['received Trips']\n",
    "    spatial_utam_date.drop(columns={'HOGARES', 'UTAMArea', 'originated Trips', 'received Trips',\n",
    "                               'N_PlazMer', 'N_Col'}, inplace=True)\n",
    "    \n",
    "    spatial_utam_date_rt = spatial_utam_date.copy()\n",
    "    spatial_utam_date_rt['ESTRATOPre'] = spatial_utam_date_rt['ESTRATOPre']/(spatial_utam_date_rt['ESTRATOPre'].max()*4)\n",
    "    spatial_utam_date_rt['PopDen[p/km2]'] = spatial_utam_date_rt['PopDen[p/km2]']/(spatial_utam_date_rt['PopDen[p/km2]'].max()*4)\n",
    "    spatial_utam_date_rt['N_Hosp'] = spatial_utam_date_rt['N_Hosp']/(spatial_utam_date_rt['N_Hosp'].max()*4)\n",
    "    spatial_utam_date_rt['N_IPS'] = spatial_utam_date_rt['N_IPS']/(spatial_utam_date_rt['N_IPS'].max()*4)\n",
    "    spatial_utam_date_rt['N_ITur']  = spatial_utam_date_rt['N_ITur']/(spatial_utam_date_rt['N_ITur'].max()*4)\n",
    "    spatial_utam_date_rt['N_SITP'] = spatial_utam_date_rt['N_SITP']/(spatial_utam_date_rt['N_SITP'].max()*4)\n",
    "    spatial_utam_date_rt['N_Ecomer'] = spatial_utam_date_rt['N_Ecomer']/(spatial_utam_date_rt['N_Ecomer'].max()*4)\n",
    "    spatial_utam_date_rt['Total trips'] = spatial_utam_date_rt['Total trips']/(spatial_utam_date_rt['Total trips'].max()*4)\n",
    "    spatial_utam_date_rt['UTAM_cases'+selec_str] = spatial_utam_date_rt['UTAM_cases'+selec_str]/(spatial_utam_date_rt['UTAM_cases'+selec_str].max()*3)\n",
    "    \n",
    "    spatial_utam_date_rt['singleRT_'+selec_str] = spatial_utam_date_rt.apply(lambda row: singularizeRT(row['LOCNombre'], row['ESTRATOPre'], \n",
    "                                                                                       row['PopDen[p/km2]'], row['N_Hosp'],\n",
    "                                                                                       row['N_IPS'], row['N_ITur'],\n",
    "                                                                                       row['N_SITP'], row['N_Ecomer'],\n",
    "                                                                                       row['Total trips'], \n",
    "                                                                                       row['UTAM_cases'+selec_str],\n",
    "                                                                                       row['Rt'+selec_str]), axis=1)\n",
    "    \n",
    "    # Finally generate final normalized DF with an estimated rt for each utam \n",
    "    spatial_utam_date['local_rt_'+selec_str] = spatial_utam_date_rt['singleRT_'+selec_str]\n",
    "\n",
    "    spatial_utam_date['ESTRATOPre'] = spatial_utam_date['ESTRATOPre']/(spatial_utam_date['ESTRATOPre'].max())\n",
    "    spatial_utam_date['PopDen[p/km2]'] = spatial_utam_date['PopDen[p/km2]']/(spatial_utam_date['PopDen[p/km2]'].max())\n",
    "    spatial_utam_date['N_Hosp'] = spatial_utam_date['N_Hosp']/(spatial_utam_date['N_Hosp'].max())\n",
    "    spatial_utam_date['N_IPS'] = spatial_utam_date['N_IPS']/(spatial_utam_date['N_IPS'].max())\n",
    "    spatial_utam_date['N_ITur']  = spatial_utam_date['N_ITur']/(spatial_utam_date['N_ITur'].max())\n",
    "    spatial_utam_date['N_SITP'] = spatial_utam_date['N_SITP']/(spatial_utam_date['N_SITP'].max())\n",
    "    spatial_utam_date['N_Ecomer'] = spatial_utam_date['N_Ecomer']/(spatial_utam_date['N_Ecomer'].max())\n",
    "    spatial_utam_date['Total trips'] = spatial_utam_date['Total trips']/(spatial_utam_date['Total trips'].max())\n",
    "    spatial_utam_date['UTAM_cases'+selec_str] = spatial_utam_date['UTAM_cases'+selec_str]/(spatial_utam_date['UTAM_cases'+selec_str].max())\n",
    "    spatial_utam_date['local_rt_'+selec_str] = spatial_utam_date['local_rt_'+selec_str]/(spatial_utam_date['local_rt_'+selec_str].max())\n",
    "    \n",
    "    spatial_utam_date.drop(columns={'Rt'+selec_str, 'cases'+selec_str}, inplace=True)\n",
    "    spatial_utam_date = spatial_utam_date[ ['LOCNombre', 'PopLoc', 'UTAM', 'LOCid', 'ESTRATOPre', 'UTAMNombre',\n",
    "                                       'PopDen[p/km2]', 'geometry', 'N_Hosp', 'N_IPS', 'N_ITur', 'N_SITP',\n",
    "                                       'N_Ecomer', 'UTAM_cases'+selec_str, 'local_rt_'+selec_str ,'Total trips'] ]\n",
    "    return spatial_utam_date\n",
    "\n",
    "def StratRisk(Cluster):\n",
    "    if Cluster == 0:\n",
    "        return 0\n",
    "    elif Cluster == 1:\n",
    "        return 2\n",
    "    elif Cluster == 2:\n",
    "        return 1\n",
    "    \n",
    "def Train_Clustering(spatial_utam):\n",
    "    selec_date = '10/01/2021'\n",
    "    selec_str = '10-01-2021'\n",
    "    selec_date = dt.datetime.strptime(selec_date, \"%d/%m/%Y\")\n",
    "\n",
    "    TrainDF = ClusteringPrepDF(selec_date, selec_str, spatial_utam)\n",
    "    TrainDF_mat = TrainDF.drop(columns={'LOCNombre', 'PopLoc','UTAM', 'LOCid', 'UTAMNombre', 'geometry', \n",
    "                                         'ESTRATOPre', 'PopDen[p/km2]', 'N_Hosp', 'N_IPS', 'N_ITur', 'N_SITP', \n",
    "                                         'N_Ecomer', 'Total trips'})\n",
    "    TrainMat = TrainDF_mat.to_numpy()\n",
    "\n",
    "    # Cluster characteristics\n",
    "    n_clust = 3\n",
    "    # Train Cluster Kmeans\n",
    "    global_kmeans = KMeans(n_clusters=n_clust, random_state=10).fit(TrainMat)\n",
    "    return global_kmeans\n",
    "\n",
    "def Calc_date(days_p, mode):\n",
    "    start = start = dt.datetime.strptime('26/3/2020', \"%d/%m/%Y\")\n",
    "    actual = start + dt.timedelta(days=days_p)\n",
    "    if mode == 0:\n",
    "        return actual\n",
    "    elif mode == 1:\n",
    "        return ( str(actual.day)+'-'+str(actual.month)+'-'+str(actual.year) )\n",
    "    \n",
    "    elif mode == 2:\n",
    "        return ( 'Day: '+str(actual.day)+' Month: '+str(actual.month)+' Year: '+str(actual.year) )\n",
    "        \n",
    "\n",
    "def Strat_Risk_Map(date, spatial_utam, global_kmeans):\n",
    "    selec_date = Calc_date(date, 0)\n",
    "    selec_str  = Calc_date(date, 1)\n",
    "\n",
    "    RiskDF = ClusteringPrepDF(selec_date, selec_str, spatial_utam)\n",
    "    RiskDFmat = RiskDF.drop(columns={'LOCNombre', 'PopLoc','UTAM', 'LOCid', 'UTAMNombre', 'geometry', \n",
    "                                         'ESTRATOPre', 'PopDen[p/km2]', 'N_Hosp', 'N_IPS', 'N_ITur', 'N_SITP', \n",
    "                                         'N_Ecomer', 'Total trips'})\n",
    "    RiskMat = RiskDFmat.to_numpy()\n",
    "    #Predict Cluster label\n",
    "    labels = global_kmeans.predict(RiskMat)\n",
    "    RiskDF['kmeans_label_full'] = labels\n",
    "    RiskDF['Risk'] = RiskDF.apply(lambda row: StratRisk(row['kmeans_label_full']), axis=1)\n",
    "    \n",
    "    #path = '/home/ubuntu/javeriana/MOTUS-PUJ/Localidades/Loca.shp'\n",
    "    path = '/home/ubuntu/javeriana/MOTUS-PUJ/Step_2/1_spatial/spatial_features/Locality/Loca.shp'\n",
    "    Localities = gpd.read_file(path)\n",
    "    Localities = Localities.sort_values(by='LocCodigo', ascending=True)\n",
    "    Localities = Localities.reset_index(drop=True)\n",
    "    Localities['LocCodigo'] = pd.to_numeric(Localities['LocCodigo'], downcast='integer')\n",
    "    Localities.to_crs(epsg=4326, inplace=True)\n",
    "    Localities.drop(columns=['LocAAdmini', 'LocArea', 'SHAPE_Leng', 'SHAPE_Area'], inplace=True)\n",
    "    Localities['LocNombre'] = Localities.apply(lambda row: Arreglar_tilde(row['LocNombre']), axis=1)\n",
    "    Localities.drop(19, axis=0, inplace=True)\n",
    "    \n",
    "    #Init folium map object for Bogotá\n",
    "    Lat = 4.61\n",
    "    Long = -74.082\n",
    "    m = folium.Map(location=[Lat, Long], zoom_start=12, tiles='CartoDB positron')\n",
    "    \n",
    "    feature_Localidad = folium.FeatureGroup(name='Localidades', overlay=True, show=False).add_to(m)\n",
    "    feature_UTAM = folium.FeatureGroup(name='UTAM', overlay=False, show=True).add_to(m)\n",
    "    \n",
    "    #Add Localities layer\n",
    "    folium.GeoJson(Localities,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'white',\n",
    "        'color': 'white',\n",
    "        'weight': 2,\n",
    "        'fillOpacity':0.2,\n",
    "    },\n",
    "    highlight_function=lambda x: {'weight':4,'fillColor':'white','color': 'white'},\n",
    "                   tooltip=folium.GeoJsonTooltip(fields=['LocNombre'],\n",
    "                                                labels=False,\n",
    "                                                sticky=True),\n",
    "    name='Localidades').add_to(feature_Localidad)\n",
    "    \n",
    "    #Add UTAM Risk Estimation Choropleth Layer\n",
    "    choropleth1 = folium.Choropleth(\n",
    "    geo_data=RiskDF,\n",
    "    name='choropleth1',\n",
    "    data=RiskDF,\n",
    "    columns=['UTAMNombre', 'Risk'],\n",
    "    key_on='feature.properties.UTAMNombre',\n",
    "    fill_color='YlOrRd',\n",
    "    nan_fill_color=\"white\",\n",
    "    fill_opacity=1,\n",
    "    line_opacity=0.2,\n",
    "    #legend_name='Risk Stratification',\n",
    "    highlight=True,\n",
    "    line_color='black').geojson.add_to(feature_UTAM)\n",
    "    \n",
    "    geojson1 = folium.GeoJson(data=RiskDF, \n",
    "                              name='UTAM', \n",
    "                              smooth_factor=2, \n",
    "                              style_function=lambda x: {'color':'black','fillColor':'transparent','weight':0.5}, \n",
    "                              tooltip=folium.GeoJsonTooltip(fields=['UTAMNombre', 'Risk'],\n",
    "                                                            aliases=['Name', 'Risk group'],\n",
    "                                                            labels=True, \n",
    "                                                            sticky=True), \n",
    "                              highlight_function=lambda x: {'weight':3,'fillColor':'grey'}, \n",
    "                             ).add_to(choropleth1)\n",
    "    #colormap = linear.YlOrRd_09.scale(0, 2).to_step(2)\n",
    "    #colormap.caption = 'Strat_risk'\n",
    "    #colormap.add_to(m)\n",
    "\n",
    "    folium.TileLayer('cartodbdark_matter', overlay=True, name=\"night mode\").add_to(m)\n",
    "    folium.LayerControl(collapsed=False).add_to(m)\n",
    "    \n",
    "    return (m.get_root().render())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:24] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:24] \"\u001b[37mGET /_dash-dependencies HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:24] \"\u001b[37mGET /_dash-layout HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:24] \"\u001b[36mGET /_dash-component-suites/dash/dcc/async-slider.js HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:29] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:03:49] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:04:28] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [13/Nov/2021 16:04:44] \"\u001b[37mPOST /_dash-update-component HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#Train Clustering\n",
    "global_kmeans = Train_Clustering(spatial_utam)\n",
    "app = dash.Dash(\n",
    "    external_stylesheets=[dbc.themes.CYBORG]\n",
    ")\n",
    "image_filename = 'Com_Risk_Scale.png' #image\n",
    "encoded_image = base64.b64encode(open(image_filename, 'rb').read())\n",
    "\n",
    "### --- Principal Title --- ### \n",
    "app.title = 'PUJ MOTUS TG'\n",
    "### ---------------- Logo - Image ------------------ ###\n",
    "\n",
    "Arriba = dbc.NavbarSimple(children=[\n",
    "html.Img(src='https://www.javeriana.edu.co/recursosdb/20129/601896/escudoPUJ-Bogota_rgb-azul_lateral.png/3eec1aa5-947a-1655-7fe7-6c4dfb397793?t=1611842495478',\n",
    "         width=230,height=100)],\n",
    "    brand=\"MOTUS Science - PUJ\",\n",
    "    brand_href=\"#\",\n",
    "    color=\"navy\",\n",
    "    dark=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Estilo_arriba_caja = {'textAlign': 'center','height': 75, 'display': 'block', \n",
    "                      'margin-left': 'auto','margin-right': 'auto','width': '100%', \n",
    "                      'color': '#ffffff',\"background-color\": 'navy'}\n",
    "\n",
    "Estilo_caja = {\"max-width\": \"2000px\", 'height': 'calc(130vh - 60px)', 'overflowY': 'scroll',\n",
    "               \"opacity\": 0.9, \"background-color\": \"black\",'textAlign': 'center', 'width': '100%'}\n",
    "\n",
    "Cuerpo = html.Div([dbc.Toast([html.Div([html.Img(src='data:image/png;base64,{}'.format(encoded_image.decode()),width=480, height=140),\n",
    "                                        html.Br(),\n",
    "    dcc.Slider(\n",
    "    id='dias_pandemia',min=0,\n",
    "    max=550,\n",
    "    value=0,\n",
    "    marks={\n",
    "        0:  {'label': '26/03/2020'},\n",
    "        60: {'label': '25/05/2020'},\n",
    "        128:{'label': '01/08/2020'},\n",
    "        220:{'label': '01/11/2020'},\n",
    "        290:{'label': '10/01/2021'},\n",
    "        349:{'label': '10/03/2021'},\n",
    "        401:{'label': '01/05/2021'},\n",
    "        451:{'label': '20/06/2021'},\n",
    "        524:{'label': '01/09/2021'}\n",
    "    },\n",
    "    included=False),html.Div(id='Resultados_mapa'),visdcc.Run_js(id='Correr_java')])],\n",
    "                    header= 'Community risk stratification map for Bogotá divided by UTAM administrative units. Select the UTAM button to observe the color scale risk stratification, check or un-check the \"Localidades\" box to show localities divisons in Bogotá. The risk score is calculated considering RT score and active cases within selected date in a UTAM'\n",
    "                             ,header_style = Estilo_arriba_caja,\n",
    "                   style=Estilo_caja)],style={\n",
    "            'marginTop': 30,\n",
    "            'marginBottom': 20,\n",
    "            'marginLeft': 250,\n",
    "            'marginRight': 250,\n",
    "            'padding': 0,'background': \"#f5f5f5\",\"opacity\": 1,})\n",
    "\n",
    "\n",
    "\n",
    "######### ---------------- Esto es un callback -------- ####### \n",
    "\n",
    "@app.callback(\n",
    "    [Output('Resultados_mapa', 'children'),\n",
    "     Output('Correr_java', 'run')],\n",
    "    [Input('dias_pandemia', 'value')])\n",
    "\n",
    "def Decision_analisis(dias_pandemia): \n",
    "    java = ''' alert(\"''' + 'Risk estimation calculated for date '+Calc_date(dias_pandemia, 2)+'''\"); '''\n",
    "    mapa = html.Section(\n",
    "        children=[html.Iframe(id='Mapa_general', srcDoc=Strat_Risk_Map(dias_pandemia, spatial_utam, global_kmeans), \n",
    "                              height = 950, \n",
    "            style={'display': 'flex','width': '100%','border': 0,\n",
    "               'top': 0,\n",
    "               'left' : 0,\n",
    "               'bottom': 0,\n",
    "               'right': 0} )],\n",
    "        style={\n",
    "            'padding': 0,\n",
    "            'margin': 0,'height': 'calc(100vh - 60px)', 'overflowY': 'scroll',\n",
    "            'borderRadius': 0,\n",
    "            'border': 'thin lightgrey ridge', 'border-color': '#c7bfbf', 'border-width': '0px',\n",
    "            'background': '#f5f5f5',\"opacity\": 0.9\n",
    "        })\n",
    "    \n",
    "    return(mapa,java)\n",
    "    \n",
    "########## ------------- Abajo ------------- ############# \n",
    "Abajo = html.Div([html.H6(\n",
    "        children='All rights reserved - Copyright ©  2021.',\n",
    "        style={'textAlign': 'center','color': 'white'})])\n",
    "\n",
    "#app.layout = html.Div(children=[Arriba, Cuerpo, Abajo])\n",
    "app.layout = html.Div(children=[Arriba, dcc.Loading(id=\"loading-1\", type=\"circle\", fullscreen=False, \n",
    "                                                                  children=[Cuerpo]), Abajo])\n",
    "\n",
    "\n",
    "############# --------------- Server ----------- ############# \n",
    "#serve(app.server,host='127.0.0.1',port=8050) #this connects with the server\n",
    "\n",
    "######## ------- Desplegar servidor -------- ########\n",
    "#server = create_server(app,threaded=True)\n",
    "#server.run()\n",
    "app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
